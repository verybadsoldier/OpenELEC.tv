Index: linux-3.17.7/drivers/net/ethernet/jme.c
===================================================================
--- linux-3.17.7.orig/drivers/net/ethernet/jme.c	2014-12-16 18:37:26.000000000 +0100
+++ linux-3.17.7/drivers/net/ethernet/jme.c	2015-01-11 16:44:13.370917900 +0100
@@ -22,12 +22,14 @@
  *
  */
 
+#include <linux/version.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,28)
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
+#endif
 
 #include <linux/module.h>
 #include <linux/kernel.h>
 #include <linux/pci.h>
-#include <linux/pci-aspm.h>
 #include <linux/netdevice.h>
 #include <linux/etherdevice.h>
 #include <linux/ethtool.h>
@@ -57,6 +59,21 @@
 MODULE_PARM_DESC(no_extplug,
 	"Do not use external plug signal for pseudo hot-plug.");
 
+#ifndef JME_NEW_PM_API
+static void
+jme_pci_wakeup_enable(struct jme_adapter *jme, int enable)
+{
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,27)
+	pci_enable_wake(jme->pdev, PCI_D1, enable);
+	pci_enable_wake(jme->pdev, PCI_D2, enable);
+	pci_enable_wake(jme->pdev, PCI_D3hot, enable);
+	pci_enable_wake(jme->pdev, PCI_D3cold, enable);
+#else
+	pci_pme_active(jme->pdev, enable);
+#endif
+}
+#endif
+
 static int
 jme_mdio_read(struct net_device *netdev, int phy, int reg)
 {
@@ -162,67 +179,6 @@
 }
 
 static inline void
-jme_mac_rxclk_off(struct jme_adapter *jme)
-{
-	jme->reg_gpreg1 |= GPREG1_RXCLKOFF;
-	jwrite32f(jme, JME_GPREG1, jme->reg_gpreg1);
-}
-
-static inline void
-jme_mac_rxclk_on(struct jme_adapter *jme)
-{
-	jme->reg_gpreg1 &= ~GPREG1_RXCLKOFF;
-	jwrite32f(jme, JME_GPREG1, jme->reg_gpreg1);
-}
-
-static inline void
-jme_mac_txclk_off(struct jme_adapter *jme)
-{
-	jme->reg_ghc &= ~(GHC_TO_CLK_SRC | GHC_TXMAC_CLK_SRC);
-	jwrite32f(jme, JME_GHC, jme->reg_ghc);
-}
-
-static inline void
-jme_mac_txclk_on(struct jme_adapter *jme)
-{
-	u32 speed = jme->reg_ghc & GHC_SPEED;
-	if (speed == GHC_SPEED_1000M)
-		jme->reg_ghc |= GHC_TO_CLK_GPHY | GHC_TXMAC_CLK_GPHY;
-	else
-		jme->reg_ghc |= GHC_TO_CLK_PCIE | GHC_TXMAC_CLK_PCIE;
-	jwrite32f(jme, JME_GHC, jme->reg_ghc);
-}
-
-static inline void
-jme_reset_ghc_speed(struct jme_adapter *jme)
-{
-	jme->reg_ghc &= ~(GHC_SPEED | GHC_DPX);
-	jwrite32f(jme, JME_GHC, jme->reg_ghc);
-}
-
-static inline void
-jme_reset_250A2_workaround(struct jme_adapter *jme)
-{
-	jme->reg_gpreg1 &= ~(GPREG1_HALFMODEPATCH |
-			     GPREG1_RSSPATCH);
-	jwrite32(jme, JME_GPREG1, jme->reg_gpreg1);
-}
-
-static inline void
-jme_assert_ghc_reset(struct jme_adapter *jme)
-{
-	jme->reg_ghc |= GHC_SWRST;
-	jwrite32f(jme, JME_GHC, jme->reg_ghc);
-}
-
-static inline void
-jme_clear_ghc_reset(struct jme_adapter *jme)
-{
-	jme->reg_ghc &= ~GHC_SWRST;
-	jwrite32f(jme, JME_GHC, jme->reg_ghc);
-}
-
-static inline void
 jme_reset_mac_processor(struct jme_adapter *jme)
 {
 	static const u32 mask[WAKEUP_FRAME_MASK_DWNR] = {0, 0, 0, 0};
@@ -230,24 +186,9 @@
 	u32 gpreg0;
 	int i;
 
-	jme_reset_ghc_speed(jme);
-	jme_reset_250A2_workaround(jme);
-
-	jme_mac_rxclk_on(jme);
-	jme_mac_txclk_on(jme);
-	udelay(1);
-	jme_assert_ghc_reset(jme);
-	udelay(1);
-	jme_mac_rxclk_off(jme);
-	jme_mac_txclk_off(jme);
-	udelay(1);
-	jme_clear_ghc_reset(jme);
-	udelay(1);
-	jme_mac_rxclk_on(jme);
-	jme_mac_txclk_on(jme);
-	udelay(1);
-	jme_mac_rxclk_off(jme);
-	jme_mac_txclk_off(jme);
+	jwrite32(jme, JME_GHC, jme->reg_ghc | GHC_SWRST);
+	udelay(2);
+	jwrite32(jme, JME_GHC, jme->reg_ghc);
 
 	jwrite32(jme, JME_RXDBA_LO, 0x00000000);
 	jwrite32(jme, JME_RXDBA_HI, 0x00000000);
@@ -267,6 +208,14 @@
 	else
 		gpreg0 = GPREG0_DEFAULT;
 	jwrite32(jme, JME_GPREG0, gpreg0);
+	jwrite32(jme, JME_GPREG1, GPREG1_DEFAULT);
+}
+
+static inline void
+jme_reset_ghc_speed(struct jme_adapter *jme)
+{
+	jme->reg_ghc &= ~(GHC_SPEED_1000M | GHC_DPX);
+	jwrite32(jme, JME_GHC, jme->reg_ghc);
 }
 
 static inline void
@@ -309,7 +258,7 @@
 jme_load_macaddr(struct net_device *netdev)
 {
 	struct jme_adapter *jme = netdev_priv(netdev);
-	unsigned char macaddr[ETH_ALEN];
+	unsigned char macaddr[6];
 	u32 val;
 
 	spin_lock_bh(&jme->macaddr_lock);
@@ -321,7 +270,7 @@
 	val = jread32(jme, JME_RXUMA_HI);
 	macaddr[4] = (val >>  0) & 0xFF;
 	macaddr[5] = (val >>  8) & 0xFF;
-	memcpy(netdev->dev_addr, macaddr, ETH_ALEN);
+	memcpy(netdev->dev_addr, macaddr, 6);
 	spin_unlock_bh(&jme->macaddr_lock);
 }
 
@@ -418,7 +367,7 @@
 jme_check_link(struct net_device *netdev, int testonly)
 {
 	struct jme_adapter *jme = netdev_priv(netdev);
-	u32 phylink, cnt = JME_SPDRSV_TIMEOUT, bmcr;
+	u32 phylink, ghc, cnt = JME_SPDRSV_TIMEOUT, bmcr, gpreg1;
 	char linkmsg[64];
 	int rc = 0;
 
@@ -481,21 +430,23 @@
 
 		jme->phylink = phylink;
 
-		/*
-		 * The speed/duplex setting of jme->reg_ghc already cleared
-		 * by jme_reset_mac_processor()
-		 */
+		ghc = jme->reg_ghc & ~(GHC_SPEED | GHC_DPX |
+				GHC_TO_CLK_PCIE | GHC_TXMAC_CLK_PCIE |
+				GHC_TO_CLK_GPHY | GHC_TXMAC_CLK_GPHY);
 		switch (phylink & PHY_LINK_SPEED_MASK) {
 		case PHY_LINK_SPEED_10M:
-			jme->reg_ghc |= GHC_SPEED_10M;
+			ghc |= GHC_SPEED_10M |
+				GHC_TO_CLK_PCIE | GHC_TXMAC_CLK_PCIE;
 			strcat(linkmsg, "10 Mbps, ");
 			break;
 		case PHY_LINK_SPEED_100M:
-			jme->reg_ghc |= GHC_SPEED_100M;
+			ghc |= GHC_SPEED_100M |
+				GHC_TO_CLK_PCIE | GHC_TXMAC_CLK_PCIE;
 			strcat(linkmsg, "100 Mbps, ");
 			break;
 		case PHY_LINK_SPEED_1000M:
-			jme->reg_ghc |= GHC_SPEED_1000M;
+			ghc |= GHC_SPEED_1000M |
+				GHC_TO_CLK_GPHY | GHC_TXMAC_CLK_GPHY;
 			strcat(linkmsg, "1000 Mbps, ");
 			break;
 		default:
@@ -505,7 +456,7 @@
 		if (phylink & PHY_LINK_DUPLEX) {
 			jwrite32(jme, JME_TXMCS, TXMCS_DEFAULT);
 			jwrite32(jme, JME_TXTRHD, TXTRHD_FULLDUPLEX);
-			jme->reg_ghc |= GHC_DPX;
+			ghc |= GHC_DPX;
 		} else {
 			jwrite32(jme, JME_TXMCS, TXMCS_DEFAULT |
 						TXMCS_BACKOFF |
@@ -514,21 +465,18 @@
 			jwrite32(jme, JME_TXTRHD, TXTRHD_HALFDUPLEX);
 		}
 
-		jwrite32(jme, JME_GHC, jme->reg_ghc);
-
+		gpreg1 = GPREG1_DEFAULT;
 		if (is_buggy250(jme->pdev->device, jme->chiprev)) {
-			jme->reg_gpreg1 &= ~(GPREG1_HALFMODEPATCH |
-					     GPREG1_RSSPATCH);
 			if (!(phylink & PHY_LINK_DUPLEX))
-				jme->reg_gpreg1 |= GPREG1_HALFMODEPATCH;
+				gpreg1 |= GPREG1_HALFMODEPATCH;
 			switch (phylink & PHY_LINK_SPEED_MASK) {
 			case PHY_LINK_SPEED_10M:
 				jme_set_phyfifo_8level(jme);
-				jme->reg_gpreg1 |= GPREG1_RSSPATCH;
+				gpreg1 |= GPREG1_RSSPATCH;
 				break;
 			case PHY_LINK_SPEED_100M:
 				jme_set_phyfifo_5level(jme);
-				jme->reg_gpreg1 |= GPREG1_RSSPATCH;
+				gpreg1 |= GPREG1_RSSPATCH;
 				break;
 			case PHY_LINK_SPEED_1000M:
 				jme_set_phyfifo_8level(jme);
@@ -537,7 +485,10 @@
 				break;
 			}
 		}
-		jwrite32(jme, JME_GPREG1, jme->reg_gpreg1);
+
+		jwrite32(jme, JME_GPREG1, gpreg1);
+		jwrite32(jme, JME_GHC, ghc);
+		jme->reg_ghc = ghc;
 
 		strcat(linkmsg, (phylink & PHY_LINK_DUPLEX) ?
 					"Full-Duplex, " :
@@ -676,14 +627,10 @@
 	 * Enable TX Engine
 	 */
 	wmb();
-	jwrite32f(jme, JME_TXCS, jme->reg_txcs |
+	jwrite32(jme, JME_TXCS, jme->reg_txcs |
 				TXCS_SELECT_QUEUE0 |
 				TXCS_ENABLE);
 
-	/*
-	 * Start clock for TX MAC Processor
-	 */
-	jme_mac_txclk_on(jme);
 }
 
 static inline void
@@ -718,11 +665,6 @@
 
 	if (!i)
 		pr_err("Disable TX engine timeout\n");
-
-	/*
-	 * Stop clock for TX MAC Processor
-	 */
-	jme_mac_txclk_off(jme);
 }
 
 static void
@@ -758,11 +700,19 @@
 		jme->dev->mtu + RX_EXTRA_LEN);
 	if (unlikely(!skb))
 		return -ENOMEM;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19)
+	skb->dev = jme->dev;
+#endif
 
 	mapping = pci_map_page(jme->pdev, virt_to_page(skb->data),
 			       offset_in_page(skb->data), skb_tailroom(skb),
 			       PCI_DMA_FROMDEVICE);
-	if (unlikely(pci_dma_mapping_error(jme->pdev, mapping))) {
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,26)
+	if (unlikely(pci_dma_mapping_error(jme->pdev, mapping)))
+#else
+	if (unlikely(pci_dma_mapping_error(mapping)))
+#endif
+	{
 		dev_kfree_skb(skb);
 		return -ENOMEM;
 	}
@@ -912,15 +862,10 @@
 	 * Enable RX Engine
 	 */
 	wmb();
-	jwrite32f(jme, JME_RXCS, jme->reg_rxcs |
+	jwrite32(jme, JME_RXCS, jme->reg_rxcs |
 				RXCS_QUEUESEL_Q0 |
 				RXCS_ENABLE |
 				RXCS_QST);
-
-	/*
-	 * Start clock for RX MAC Processor
-	 */
-	jme_mac_rxclk_on(jme);
 }
 
 static inline void
@@ -957,21 +902,35 @@
 	if (!i)
 		pr_err("Disable RX engine timeout\n");
 
-	/*
-	 * Stop clock for RX MAC Processor
-	 */
-	jme_mac_rxclk_off(jme);
 }
 
 static u16
 jme_udpsum(struct sk_buff *skb)
 {
 	u16 csum = 0xFFFFu;
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,21)
+	struct iphdr *iph;
+	int iphlen;
+	struct udphdr *udph;
+#endif
 
 	if (skb->len < (ETH_HLEN + sizeof(struct iphdr)))
 		return csum;
 	if (skb->protocol != htons(ETH_P_IP))
 		return csum;
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,21)
+	iph = (struct iphdr *)skb_pull(skb, ETH_HLEN);
+	iphlen = (iph->ihl << 2);
+	if ((iph->protocol != IPPROTO_UDP) ||
+	    (skb->len < (iphlen + sizeof(struct udphdr)))) {
+		skb_push(skb, ETH_HLEN);
+		return csum;
+	}
+	udph = (struct udphdr *)skb_pull(skb, iphlen);
+	csum = udph->check;
+	skb_push(skb, iphlen);
+	skb_push(skb, ETH_HLEN);
+#else
 	skb_set_network_header(skb, ETH_HLEN);
 	if ((ip_hdr(skb)->protocol != IPPROTO_UDP) ||
 	    (skb->len < (ETH_HLEN +
@@ -985,6 +944,7 @@
 	csum = udp_hdr(skb)->check;
 	skb_reset_transport_header(skb);
 	skb_reset_network_header(skb);
+#endif
 
 	return csum;
 }
@@ -1054,15 +1014,33 @@
 		if (jme_rxsum_ok(jme, le16_to_cpu(rxdesc->descwb.flags), skb))
 			skb->ip_summed = CHECKSUM_UNNECESSARY;
 		else
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,36)
+			skb->ip_summed = CHECKSUM_NONE;
+#else
 			skb_checksum_none_assert(skb);
+#endif
 
+#ifndef __UNIFY_VLAN_RX_PATH__
+		if (rxdesc->descwb.flags & cpu_to_le16(RXWBFLAG_TAGON)) {
+			if (jme->vlgrp) {
+				jme->jme_vlan_rx(skb, jme->vlgrp,
+					le16_to_cpu(rxdesc->descwb.vlan));
+				NET_STAT(jme).rx_bytes += 4;
+			} else {
+				dev_kfree_skb(skb);
+			}
+		} else {
+			jme->jme_rx(skb);
+		}
+#else
 		if (rxdesc->descwb.flags & cpu_to_le16(RXWBFLAG_TAGON)) {
 			u16 vid = le16_to_cpu(rxdesc->descwb.vlan);
 
-			__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vid);
+			__vlan_hwaccel_put_tag(skb, vid);
 			NET_STAT(jme).rx_bytes += 4;
 		}
 		jme->jme_rx(skb);
+#endif
 
 		if ((rxdesc->descwb.flags & cpu_to_le16(RXWBFLAG_DEST)) ==
 		    cpu_to_le16(RXWBFLAG_DEST_MUL))
@@ -1319,6 +1297,7 @@
 	tasklet_disable(&jme->rxempty_task);
 
 	if (netif_carrier_ok(netdev)) {
+		jme_reset_ghc_speed(jme);
 		jme_disable_rx_engine(jme);
 		jme_disable_tx_engine(jme);
 		jme_reset_mac_processor(jme);
@@ -1385,6 +1364,7 @@
 jme_poll(JME_NAPI_HOLDER(holder), JME_NAPI_WEIGHT(budget))
 {
 	struct jme_adapter *jme = jme_napi_priv(holder);
+	DECLARE_NETDEV
 	int rest;
 
 	rest = jme_process_receive(jme, JME_NAPI_WEIGHT_VAL(budget));
@@ -1585,8 +1565,13 @@
 	jwrite32f(jme, JME_IENS, INTR_ENABLE);
 }
 
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
+static irqreturn_t
+jme_intr(int irq, void *dev_id, struct pt_regs *regs)
+#else
 static irqreturn_t
 jme_intr(int irq, void *dev_id)
+#endif
 {
 	struct net_device *netdev = dev_id;
 	struct jme_adapter *jme = netdev_priv(netdev);
@@ -1611,8 +1596,13 @@
 	return IRQ_HANDLED;
 }
 
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
+static irqreturn_t
+jme_msi(int irq, void *dev_id, struct pt_regs *regs)
+#else
 static irqreturn_t
 jme_msi(int irq, void *dev_id)
+#endif
 {
 	struct net_device *netdev = dev_id;
 	struct jme_adapter *jme = netdev_priv(netdev);
@@ -1648,8 +1638,13 @@
 {
 	int rc;
 	struct net_device *netdev = jme->dev;
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
+	irqreturn_t (*handler)(int, void *, struct pt_regs *) = jme_intr;
+	int irq_flags = SA_SHIRQ;
+#else
 	irq_handler_t handler = jme_intr;
 	int irq_flags = IRQF_SHARED;
+#endif
 
 	if (!pci_enable_msi(jme->pdev)) {
 		set_bit(JME_FLAG_MSI, &jme->flags);
@@ -1860,14 +1855,10 @@
 	jme_clear_pm(jme);
 	JME_NAPI_ENABLE(jme);
 
-	tasklet_init(&jme->linkch_task, jme_link_change_tasklet,
-		     (unsigned long) jme);
-	tasklet_init(&jme->txclean_task, jme_tx_clean_tasklet,
-		     (unsigned long) jme);
-	tasklet_init(&jme->rxclean_task, jme_rx_clean_tasklet,
-		     (unsigned long) jme);
-	tasklet_init(&jme->rxempty_task, jme_rx_empty_tasklet,
-		     (unsigned long) jme);
+	tasklet_enable(&jme->linkch_task);
+	tasklet_enable(&jme->txclean_task);
+	tasklet_hi_enable(&jme->rxclean_task);
+	tasklet_hi_enable(&jme->rxempty_task);
 
 	rc = jme_request_irq(jme);
 	if (rc)
@@ -1952,11 +1943,12 @@
 
 	JME_NAPI_DISABLE(jme);
 
-	tasklet_kill(&jme->linkch_task);
-	tasklet_kill(&jme->txclean_task);
-	tasklet_kill(&jme->rxclean_task);
-	tasklet_kill(&jme->rxempty_task);
+	tasklet_disable(&jme->linkch_task);
+	tasklet_disable(&jme->txclean_task);
+	tasklet_disable(&jme->rxclean_task);
+	tasklet_disable(&jme->rxempty_task);
 
+	jme_reset_ghc_speed(jme);
 	jme_disable_rx_engine(jme);
 	jme_disable_tx_engine(jme);
 	jme_reset_mac_processor(jme);
@@ -1988,14 +1980,19 @@
 	return idx;
 }
 
-static int
+static void
 jme_fill_tx_map(struct pci_dev *pdev,
 		struct txdesc *txdesc,
 		struct jme_buffer_info *txbi,
 		struct page *page,
 		u32 page_offset,
 		u32 len,
-		bool hidma)
+#ifdef __NO_BOOL__
+		u8 hidma
+#else
+		bool hidma
+#endif
+		)
 {
 	dma_addr_t dmaaddr;
 
@@ -2005,9 +2002,6 @@
 				len,
 				PCI_DMA_TODEVICE);
 
-	if (unlikely(pci_dma_mapping_error(pdev, dmaaddr)))
-		return -EINVAL;
-
 	pci_dma_sync_single_for_device(pdev,
 				       dmaaddr,
 				       len,
@@ -2024,75 +2018,73 @@
 
 	txbi->mapping = dmaaddr;
 	txbi->len = len;
-	return 0;
-}
-
-static void jme_drop_tx_map(struct jme_adapter *jme, int startidx, int count)
-{
-	struct jme_ring *txring = &(jme->txring[0]);
-	struct jme_buffer_info *txbi = txring->bufinf, *ctxbi;
-	int mask = jme->tx_ring_mask;
-	int j;
-
-	for (j = 0 ; j < count ; j++) {
-		ctxbi = txbi + ((startidx + j + 2) & (mask));
-		pci_unmap_page(jme->pdev,
-				ctxbi->mapping,
-				ctxbi->len,
-				PCI_DMA_TODEVICE);
-
-				ctxbi->mapping = 0;
-				ctxbi->len = 0;
-	}
-
 }
 
-static int
+static void
 jme_map_tx_skb(struct jme_adapter *jme, struct sk_buff *skb, int idx)
 {
 	struct jme_ring *txring = &(jme->txring[0]);
 	struct txdesc *txdesc = txring->desc, *ctxdesc;
 	struct jme_buffer_info *txbi = txring->bufinf, *ctxbi;
+#ifdef __NO_BOOL__
+	u8 hidma = !!(jme->dev->features & NETIF_F_HIGHDMA);
+#else
 	bool hidma = jme->dev->features & NETIF_F_HIGHDMA;
+#endif
 	int i, nr_frags = skb_shinfo(skb)->nr_frags;
 	int mask = jme->tx_ring_mask;
 	const struct skb_frag_struct *frag;
 	u32 len;
-	int ret = 0;
 
 	for (i = 0 ; i < nr_frags ; ++i) {
 		frag = &skb_shinfo(skb)->frags[i];
 		ctxdesc = txdesc + ((idx + i + 2) & (mask));
 		ctxbi = txbi + ((idx + i + 2) & (mask));
 
-		ret = jme_fill_tx_map(jme->pdev, ctxdesc, ctxbi,
+#ifndef __USE_SKB_FRAG_API__
+		jme_fill_tx_map(jme->pdev, ctxdesc, ctxbi, frag->page,
+				 frag->page_offset, frag->size, hidma);
+#else
+		jme_fill_tx_map(jme->pdev, ctxdesc, ctxbi,
 				skb_frag_page(frag),
 				frag->page_offset, skb_frag_size(frag), hidma);
-		if (ret) {
-			jme_drop_tx_map(jme, idx, i);
-			goto out;
-		}
-
+#endif
 	}
 
 	len = skb_is_nonlinear(skb) ? skb_headlen(skb) : skb->len;
 	ctxdesc = txdesc + ((idx + 1) & (mask));
 	ctxbi = txbi + ((idx + 1) & (mask));
-	ret = jme_fill_tx_map(jme->pdev, ctxdesc, ctxbi, virt_to_page(skb->data),
+	jme_fill_tx_map(jme->pdev, ctxdesc, ctxbi, virt_to_page(skb->data),
 			offset_in_page(skb->data), len, hidma);
-	if (ret)
-		jme_drop_tx_map(jme, idx, i);
-
-out:
-	return ret;
 
 }
 
+static int
+jme_expand_header(struct jme_adapter *jme, struct sk_buff *skb)
+{
+	if (unlikely(
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,17)
+	skb_shinfo(skb)->tso_size
+#else
+	skb_shinfo(skb)->gso_size
+#endif
+			&& skb_header_cloned(skb) &&
+			pskb_expand_head(skb, 0, 0, GFP_ATOMIC))) {
+		dev_kfree_skb(skb);
+		return -1;
+	}
+
+	return 0;
+}
 
 static int
 jme_tx_tso(struct sk_buff *skb, __le16 *mss, u8 *flags)
 {
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,17)
+	*mss = cpu_to_le16(skb_shinfo(skb)->tso_size << TXDESC_MSS_SHIFT);
+#else
 	*mss = cpu_to_le16(skb_shinfo(skb)->gso_size << TXDESC_MSS_SHIFT);
+#endif
 	if (*mss) {
 		*flags |= TXFLAG_LSEN;
 
@@ -2122,9 +2114,22 @@
 static void
 jme_tx_csum(struct jme_adapter *jme, struct sk_buff *skb, u8 *flags)
 {
-	if (skb->ip_summed == CHECKSUM_PARTIAL) {
+#ifdef CHECKSUM_PARTIAL
+	if (skb->ip_summed == CHECKSUM_PARTIAL)
+#else
+	if (skb->ip_summed == CHECKSUM_HW)
+#endif
+	{
 		u8 ip_proto;
 
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,21)
+		if (skb->protocol == htons(ETH_P_IP))
+			ip_proto = ip_hdr(skb)->protocol;
+		else if (skb->protocol == htons(ETH_P_IPV6))
+			ip_proto = ipv6_hdr(skb)->nexthdr;
+		else
+			ip_proto = 0;
+#else
 		switch (skb->protocol) {
 		case htons(ETH_P_IP):
 			ip_proto = ip_hdr(skb)->protocol;
@@ -2136,6 +2141,7 @@
 			ip_proto = 0;
 			break;
 		}
+#endif
 
 		switch (ip_proto) {
 		case IPPROTO_TCP:
@@ -2167,7 +2173,6 @@
 	struct txdesc *txdesc;
 	struct jme_buffer_info *txbi;
 	u8 flags;
-	int ret = 0;
 
 	txdesc = (struct txdesc *)txring->desc + idx;
 	txbi = txring->bufinf + idx;
@@ -2192,10 +2197,7 @@
 	if (jme_tx_tso(skb, &txdesc->desc1.mss, &flags))
 		jme_tx_csum(jme, skb, &flags);
 	jme_tx_vlan(skb, &txdesc->desc1.vlan, &flags);
-	ret = jme_map_tx_skb(jme, skb, idx);
-	if (ret)
-		return ret;
-
+	jme_map_tx_skb(jme, skb, idx);
 	txdesc->desc1.flags = flags;
 	/*
 	 * Set tx buffer info after telling NIC to send
@@ -2246,14 +2248,17 @@
  * This function is already protected by netif_tx_lock()
  */
 
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,31)
+static int
+#else
 static netdev_tx_t
+#endif
 jme_start_xmit(struct sk_buff *skb, struct net_device *netdev)
 {
 	struct jme_adapter *jme = netdev_priv(netdev);
 	int idx;
 
-	if (unlikely(skb_is_gso(skb) && skb_cow_head(skb, 0))) {
-		dev_kfree_skb_any(skb);
+	if (unlikely(jme_expand_header(jme, skb))) {
 		++(NET_STAT(jme).tx_dropped);
 		return NETDEV_TX_OK;
 	}
@@ -2268,13 +2273,15 @@
 		return NETDEV_TX_BUSY;
 	}
 
-	if (jme_fill_tx_desc(jme, skb, idx))
-		return NETDEV_TX_OK;
+	jme_fill_tx_desc(jme, skb, idx);
 
 	jwrite32(jme, JME_TXCS, jme->reg_txcs |
 				TXCS_SELECT_QUEUE0 |
 				TXCS_QUEUE0S |
 				TXCS_ENABLE);
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,29)
+	netdev->trans_start = jiffies;
+#endif
 
 	tx_dbg(jme, "xmit: %d+%d@%lu\n",
 	       idx, skb_shinfo(skb)->nr_frags + 2, jiffies);
@@ -2321,6 +2328,9 @@
 {
 	struct jme_adapter *jme = netdev_priv(netdev);
 	u32 mc_hash[2] = {};
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,33)
+	int i;
+#endif
 
 	spin_lock_bh(&jme->rxmcs_lock);
 
@@ -2331,12 +2341,28 @@
 	} else if (netdev->flags & IFF_ALLMULTI) {
 		jme->reg_rxmcs |= RXMCS_ALLMULFRAME;
 	} else if (netdev->flags & IFF_MULTICAST) {
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,34)
+		struct dev_mc_list *mclist;
+#else
 		struct netdev_hw_addr *ha;
+#endif
 		int bit_nr;
 
 		jme->reg_rxmcs |= RXMCS_MULFRAME | RXMCS_MULFILTERED;
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,33)
+		for (i = 0, mclist = netdev->mc_list;
+			mclist && i < netdev->mc_count;
+			++i, mclist = mclist->next) {
+#elif LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,34)
+		netdev_for_each_mc_addr(mclist, netdev) {
+#else
 		netdev_for_each_mc_addr(ha, netdev) {
+#endif
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,34)
+			bit_nr = ether_crc(ETH_ALEN, mclist->dmi_addr) & 0x3F;
+#else
 			bit_nr = ether_crc(ETH_ALEN, ha->addr) & 0x3F;
+#endif
 			mc_hash[bit_nr >> 5] |= 1 << (bit_nr & 0x1F);
 		}
 
@@ -2363,8 +2389,22 @@
 		return -EINVAL;
 
 
+#ifndef __USE_NDO_FIX_FEATURES__
+	if (new_mtu > 1900) {
+		netdev->features &= ~(NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM |
+				NETIF_F_TSO | NETIF_F_TSO6);
+	} else {
+		if (test_bit(JME_FLAG_TXCSUM, &jme->flags))
+			netdev->features |= NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM;
+		if (test_bit(JME_FLAG_TSO, &jme->flags))
+			netdev->features |= NETIF_F_TSO | NETIF_F_TSO6;
+	}
+#endif
+
 	netdev->mtu = new_mtu;
+#ifdef __USE_NDO_FIX_FEATURES__
 	netdev_update_features(netdev);
+#endif
 
 	jme_restart_rx_engine(jme);
 	jme_reset_link(jme);
@@ -2419,6 +2459,36 @@
 	atomic_inc(&jme->link_changing);
 }
 
+#ifndef __UNIFY_VLAN_RX_PATH__
+static void
+jme_vlan_rx_register(struct net_device *netdev, struct vlan_group *grp)
+{
+	struct jme_adapter *jme = netdev_priv(netdev);
+
+	jme_pause_rx(jme);
+	jme->vlgrp = grp;
+	jme_resume_rx(jme);
+}
+#endif
+
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,21)
+static void
+jme_vlan_rx_kill_vid(struct net_device *netdev, unsigned short vid)
+{
+	struct jme_adapter *jme = netdev_priv(netdev);
+
+	if(jme->vlgrp) {
+		jme_pause_rx(jme);
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,20)
+		jme->vlgrp->vlan_devices[vid] = NULL;
+#else
+		vlan_group_set_device(jme->vlgrp, vid, NULL);
+#endif
+		jme_resume_rx(jme);
+	}
+}
+#endif
+
 static void
 jme_get_drvinfo(struct net_device *netdev,
 		     struct ethtool_drvinfo *info)
@@ -2529,6 +2599,9 @@
 	    test_bit(JME_FLAG_POLL, &jme->flags)) {
 		clear_bit(JME_FLAG_POLL, &jme->flags);
 		jme->jme_rx = netif_rx;
+#ifndef __UNIFY_VLAN_RX_PATH__
+		jme->jme_vlan_rx = vlan_hwaccel_rx;
+#endif
 		dpi->cur		= PCC_P1;
 		dpi->attempt		= PCC_P1;
 		dpi->cnt		= 0;
@@ -2538,6 +2611,9 @@
 		   !(test_bit(JME_FLAG_POLL, &jme->flags))) {
 		set_bit(JME_FLAG_POLL, &jme->flags);
 		jme->jme_rx = netif_receive_skb;
+#ifndef __UNIFY_VLAN_RX_PATH__
+		jme->jme_vlan_rx = vlan_hwaccel_receive_skb;
+#endif
 		jme_interrupt_mode(jme);
 	}
 
@@ -2651,7 +2727,12 @@
 		jme->reg_pmcs |= PMCS_MFEN;
 
 	jwrite32(jme, JME_PMCS, jme->reg_pmcs);
+#ifndef JME_NEW_PM_API
+	jme_pci_wakeup_enable(jme, !!(jme->reg_pmcs));
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
 	device_set_wakeup_enable(&jme->pdev->dev, !!(jme->reg_pmcs));
+#endif
 
 	return 0;
 }
@@ -2753,8 +2834,73 @@
 	jme->msg_enable = value;
 }
 
+#ifndef __USE_NDO_FIX_FEATURES__
+static u32
+jme_get_rx_csum(struct net_device *netdev)
+{
+	struct jme_adapter *jme = netdev_priv(netdev);
+	return jme->reg_rxmcs & RXMCS_CHECKSUM;
+}
+
+static int
+jme_set_rx_csum(struct net_device *netdev, u32 on)
+{
+	struct jme_adapter *jme = netdev_priv(netdev);
+
+	spin_lock_bh(&jme->rxmcs_lock);
+	if (on)
+		jme->reg_rxmcs |= RXMCS_CHECKSUM;
+	else
+		jme->reg_rxmcs &= ~RXMCS_CHECKSUM;
+	jwrite32(jme, JME_RXMCS, jme->reg_rxmcs);
+	spin_unlock_bh(&jme->rxmcs_lock);
+
+	return 0;
+}
+
+static int
+jme_set_tx_csum(struct net_device *netdev, u32 on)
+{
+	struct jme_adapter *jme = netdev_priv(netdev);
+
+	if (on) {
+		set_bit(JME_FLAG_TXCSUM, &jme->flags);
+		if (netdev->mtu <= 1900)
+			netdev->features |=
+				NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM;
+	} else {
+		clear_bit(JME_FLAG_TXCSUM, &jme->flags);
+		netdev->features &=
+				~(NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM);
+	}
+
+	return 0;
+}
+
+static int
+jme_set_tso(struct net_device *netdev, u32 on)
+{
+	struct jme_adapter *jme = netdev_priv(netdev);
+
+	if (on) {
+		set_bit(JME_FLAG_TSO, &jme->flags);
+		if (netdev->mtu <= 1900)
+			netdev->features |= NETIF_F_TSO | NETIF_F_TSO6;
+	} else {
+		clear_bit(JME_FLAG_TSO, &jme->flags);
+		netdev->features &= ~(NETIF_F_TSO | NETIF_F_TSO6);
+	}
+
+	return 0;
+}
+#else
+#ifndef __NEW_FIX_FEATURES_TYPE__
+static u32
+jme_fix_features(struct net_device *netdev, u32 features)
+#else
 static netdev_features_t
 jme_fix_features(struct net_device *netdev, netdev_features_t features)
+#endif
 {
 	if (netdev->mtu > 1900)
 		features &= ~(NETIF_F_ALL_TSO | NETIF_F_ALL_CSUM);
@@ -2762,7 +2908,11 @@
 }
 
 static int
+#ifndef __NEW_FIX_FEATURES_TYPE__
+jme_set_features(struct net_device *netdev, u32 features)
+#else
 jme_set_features(struct net_device *netdev, netdev_features_t features)
+#endif
 {
 	struct jme_adapter *jme = netdev_priv(netdev);
 
@@ -2776,16 +2926,6 @@
 
 	return 0;
 }
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-static void jme_netpoll(struct net_device *dev)
-{
-	unsigned long flags;
-
-	local_irq_save(flags);
-	jme_intr(dev->irq, dev);
-	local_irq_restore(flags);
-}
 #endif
 
 static int
@@ -2914,7 +3054,11 @@
 	return 0;
 }
 
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
+static struct ethtool_ops jme_ethtool_ops = {
+#else
 static const struct ethtool_ops jme_ethtool_ops = {
+#endif
 	.get_drvinfo            = jme_get_drvinfo,
 	.get_regs_len		= jme_get_regs_len,
 	.get_regs		= jme_get_regs,
@@ -2929,6 +3073,13 @@
 	.get_link		= jme_get_link,
 	.get_msglevel           = jme_get_msglevel,
 	.set_msglevel           = jme_set_msglevel,
+#ifndef __USE_NDO_FIX_FEATURES__
+	.get_rx_csum		= jme_get_rx_csum,
+	.set_rx_csum		= jme_set_rx_csum,
+	.set_tx_csum		= jme_set_tx_csum,
+	.set_tso		= jme_set_tso,
+	.set_sg			= ethtool_op_set_sg,
+#endif
 	.nway_reset             = jme_nway_reset,
 	.get_eeprom_len		= jme_get_eeprom_len,
 	.get_eeprom		= jme_get_eeprom,
@@ -2939,17 +3090,40 @@
 jme_pci_dma64(struct pci_dev *pdev)
 {
 	if (pdev->device == PCI_DEVICE_ID_JMICRON_JMC250 &&
-	    !pci_set_dma_mask(pdev, DMA_BIT_MASK(64)))
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,29)
+	    !pci_set_dma_mask(pdev, DMA_BIT_MASK(64))
+#else
+	    !pci_set_dma_mask(pdev, DMA_64BIT_MASK)
+#endif
+	   )
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,29)
 		if (!pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64)))
+#else
+		if (!pci_set_consistent_dma_mask(pdev, DMA_64BIT_MASK))
+#endif
 			return 1;
 
 	if (pdev->device == PCI_DEVICE_ID_JMICRON_JMC250 &&
-	    !pci_set_dma_mask(pdev, DMA_BIT_MASK(40)))
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,29)
+	    !pci_set_dma_mask(pdev, DMA_BIT_MASK(40))
+#else
+	    !pci_set_dma_mask(pdev, DMA_40BIT_MASK)
+#endif
+	   )
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,29)
 		if (!pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(40)))
+#else
+		if (!pci_set_consistent_dma_mask(pdev, DMA_40BIT_MASK))
+#endif
 			return 1;
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,29)
 	if (!pci_set_dma_mask(pdev, DMA_BIT_MASK(32)))
 		if (!pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32)))
+#else
+	if (!pci_set_dma_mask(pdev, DMA_32BIT_MASK))
+		if (!pci_set_consistent_dma_mask(pdev, DMA_32BIT_MASK))
+#endif
 			return 0;
 
 	return -1;
@@ -2977,6 +3151,7 @@
 	jme->chip_sub_rev = (jme->chiprev >> 4) & 0xF;
 }
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,29)
 static const struct net_device_ops jme_netdev_ops = {
 	.ndo_open		= jme_open,
 	.ndo_stop		= jme_close,
@@ -2984,15 +3159,22 @@
 	.ndo_do_ioctl		= jme_ioctl,
 	.ndo_start_xmit		= jme_start_xmit,
 	.ndo_set_mac_address	= jme_set_macaddr,
+#ifndef __USE_NDO_SET_RX_MODE__
+	.ndo_set_multicast_list	= jme_set_multi,
+#else
 	.ndo_set_rx_mode	= jme_set_multi,
+#endif
 	.ndo_change_mtu		= jme_change_mtu,
 	.ndo_tx_timeout		= jme_tx_timeout,
+#ifndef __UNIFY_VLAN_RX_PATH__
+	.ndo_vlan_rx_register	= jme_vlan_rx_register,
+#endif
+#ifdef __USE_NDO_FIX_FEATURES__
 	.ndo_fix_features       = jme_fix_features,
 	.ndo_set_features       = jme_set_features,
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	.ndo_poll_controller	= jme_netpoll,
 #endif
 };
+#endif
 
 static int
 jme_init_one(struct pci_dev *pdev,
@@ -3007,9 +3189,6 @@
 	/*
 	 * set up PCI device basics
 	 */
-	pci_disable_link_state(pdev, PCIE_LINK_STATE_L0S | PCIE_LINK_STATE_L1 |
-			       PCIE_LINK_STATE_CLKPM);
-
 	rc = pci_enable_device(pdev);
 	if (rc) {
 		pr_err("Cannot enable PCI device\n");
@@ -3045,22 +3224,40 @@
 		rc = -ENOMEM;
 		goto err_out_release_regions;
 	}
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,29)
 	netdev->netdev_ops = &jme_netdev_ops;
+#else
+	netdev->open			= jme_open;
+	netdev->stop			= jme_close;
+	netdev->do_ioctl		= jme_ioctl;
+	netdev->hard_start_xmit		= jme_start_xmit;
+	netdev->set_mac_address		= jme_set_macaddr;
+	netdev->set_multicast_list	= jme_set_multi;
+	netdev->change_mtu		= jme_change_mtu;
+	netdev->tx_timeout		= jme_tx_timeout;
+	netdev->vlan_rx_register	= jme_vlan_rx_register;
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,21)
+	netdev->vlan_rx_kill_vid	= jme_vlan_rx_kill_vid;
+#endif
+	NETDEV_GET_STATS(netdev, &jme_get_stats);
+#endif
 	netdev->ethtool_ops		= &jme_ethtool_ops;
 	netdev->watchdog_timeo		= TX_TIMEOUT;
+#ifdef __USE_NDO_FIX_FEATURES__
 	netdev->hw_features		=	NETIF_F_IP_CSUM |
 						NETIF_F_IPV6_CSUM |
 						NETIF_F_SG |
 						NETIF_F_TSO |
 						NETIF_F_TSO6 |
 						NETIF_F_RXCSUM;
+#endif
 	netdev->features		=	NETIF_F_IP_CSUM |
 						NETIF_F_IPV6_CSUM |
 						NETIF_F_SG |
 						NETIF_F_TSO |
 						NETIF_F_TSO6 |
-						NETIF_F_HW_VLAN_CTAG_TX |
-						NETIF_F_HW_VLAN_CTAG_RX;
+						NETIF_F_HW_VLAN_TX |
+						NETIF_F_HW_VLAN_RX;
 	if (using_dac)
 		netdev->features	|=	NETIF_F_HIGHDMA;
 
@@ -3074,6 +3271,9 @@
 	jme->pdev = pdev;
 	jme->dev = netdev;
 	jme->jme_rx = netif_rx;
+#ifndef __UNIFY_VLAN_RX_PATH__
+	jme->jme_vlan_rx = vlan_hwaccel_rx;
+#endif
 	jme->old_mtu = netdev->mtu = 1500;
 	jme->phylink = 0;
 	jme->tx_ring_size = 1 << 10;
@@ -3098,7 +3298,7 @@
 		jwrite32(jme, JME_APMC, apmc);
 	}
 
-	NETIF_NAPI_SET(netdev, &jme->napi, jme_poll, NAPI_POLL_WEIGHT)
+	NETIF_NAPI_SET(netdev, &jme->napi, jme_poll, jme->rx_ring_size >> 2)
 
 	spin_lock_init(&jme->phy_lock);
 	spin_lock_init(&jme->macaddr_lock);
@@ -3112,6 +3312,22 @@
 	tasklet_init(&jme->pcc_task,
 		     jme_pcc_tasklet,
 		     (unsigned long) jme);
+	tasklet_init(&jme->linkch_task,
+		     jme_link_change_tasklet,
+		     (unsigned long) jme);
+	tasklet_init(&jme->txclean_task,
+		     jme_tx_clean_tasklet,
+		     (unsigned long) jme);
+	tasklet_init(&jme->rxclean_task,
+		     jme_rx_clean_tasklet,
+		     (unsigned long) jme);
+	tasklet_init(&jme->rxempty_task,
+		     jme_rx_empty_tasklet,
+		     (unsigned long) jme);
+	tasklet_disable_nosync(&jme->linkch_task);
+	tasklet_disable_nosync(&jme->txclean_task);
+	tasklet_disable_nosync(&jme->rxclean_task);
+	tasklet_disable_nosync(&jme->rxempty_task);
 	jme->dpi.cur = PCC_P1;
 
 	jme->reg_ghc = 0;
@@ -3119,10 +3335,14 @@
 	jme->reg_rxmcs = RXMCS_DEFAULT;
 	jme->reg_txpfc = 0;
 	jme->reg_pmcs = PMCS_MFEN;
-	jme->reg_gpreg1 = GPREG1_DEFAULT;
+#ifndef __USE_NDO_FIX_FEATURES__
+	set_bit(JME_FLAG_TXCSUM, &jme->flags);
+	set_bit(JME_FLAG_TSO, &jme->flags);
+#else
 
 	if (jme->reg_rxmcs & RXMCS_CHECKSUM)
 		netdev->features |= NETIF_F_RXCSUM;
+#endif
 
 	/*
 	 * Get Max Read Req Size from PCI Config Space
@@ -3177,10 +3397,20 @@
 	jme->mii_if.mdio_write = jme_mdio_write;
 
 	jme_clear_pm(jme);
+	pci_set_power_state(jme->pdev, PCI_D0);
+#ifndef JME_NEW_PM_API
+	jme_pci_wakeup_enable(jme, true);
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
 	device_set_wakeup_enable(&pdev->dev, true);
+#endif
 
 	jme_set_phyfifo_5level(jme);
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,22)
+	pci_read_config_byte(pdev, PCI_REVISION_ID, &jme->pcirev);
+#else
 	jme->pcirev = pdev->revision;
+#endif
 	if (!jme->fpgaver)
 		jme_phy_init(jme);
 	jme_phy_off(jme);
@@ -3207,20 +3437,28 @@
 		goto err_out_unmap;
 	}
 
-	netif_info(jme, probe, jme->dev, "%s%s chiprev:%x pcirev:%x macaddr:%pM\n",
+	netif_info(jme, probe, jme->dev, "%s%s chipver:%x pcirev:%x "
+		   "macaddr: %02x:%02x:%02x:%02x:%02x:%02x\n",
 		   (jme->pdev->device == PCI_DEVICE_ID_JMICRON_JMC250) ?
 		   "JMC250 Gigabit Ethernet" :
 		   (jme->pdev->device == PCI_DEVICE_ID_JMICRON_JMC260) ?
 		   "JMC260 Fast Ethernet" : "Unknown",
 		   (jme->fpgaver != 0) ? " (FPGA)" : "",
 		   (jme->fpgaver != 0) ? jme->fpgaver : jme->chiprev,
-		   jme->pcirev, netdev->dev_addr);
+		   jme->pcirev,
+		   netdev->dev_addr[0],
+		   netdev->dev_addr[1],
+		   netdev->dev_addr[2],
+		   netdev->dev_addr[3],
+		   netdev->dev_addr[4],
+		   netdev->dev_addr[5]);
 
 	return 0;
 
 err_out_unmap:
 	iounmap(jme->regs);
 err_out_free_netdev:
+	pci_set_drvdata(pdev, NULL);
 	free_netdev(netdev);
 err_out_release_regions:
 	pci_release_regions(pdev);
@@ -3238,6 +3476,7 @@
 
 	unregister_netdev(netdev);
 	iounmap(jme->regs);
+	pci_set_drvdata(pdev, NULL);
 	free_netdev(netdev);
 	pci_release_regions(pdev);
 	pci_disable_device(pdev);
@@ -3251,20 +3490,38 @@
 	struct jme_adapter *jme = netdev_priv(netdev);
 
 	jme_powersave_phy(jme);
-	pci_pme_active(pdev, true);
+#ifndef JME_NEW_PM_API
+	jme_pci_wakeup_enable(jme, !!(jme->reg_pmcs));
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+	device_set_wakeup_enable(&jme->pdev->dev, !!(jme->reg_pmcs));
+#endif
 }
 
-#ifdef CONFIG_PM_SLEEP
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,25)
+	#ifdef CONFIG_PM
+		#define JME_HAVE_PM
+	#endif
+#else
+	#ifdef CONFIG_PM_SLEEP
+		#define JME_HAVE_PM
+	#endif
+#endif
+
+#ifdef JME_HAVE_PM
 static int
+#ifdef JME_NEW_PM_API
 jme_suspend(struct device *dev)
+#else
+jme_suspend(struct pci_dev *pdev, pm_message_t state)
+#endif
 {
+#ifdef JME_NEW_PM_API
 	struct pci_dev *pdev = to_pci_dev(dev);
+#endif
 	struct net_device *netdev = pci_get_drvdata(pdev);
 	struct jme_adapter *jme = netdev_priv(netdev);
 
-	if (!netif_running(netdev))
-		return 0;
-
 	atomic_dec(&jme->link_changing);
 
 	netif_device_detach(netdev);
@@ -3280,6 +3537,7 @@
 			jme_polling_mode(jme);
 
 		jme_stop_pcc_timer(jme);
+		jme_reset_ghc_speed(jme);
 		jme_disable_rx_engine(jme);
 		jme_disable_tx_engine(jme);
 		jme_reset_mac_processor(jme);
@@ -3294,21 +3552,34 @@
 	tasklet_hi_enable(&jme->rxempty_task);
 
 	jme_powersave_phy(jme);
+#ifndef JME_NEW_PM_API
+	pci_save_state(pdev);
+	jme_pci_wakeup_enable(jme, !!(jme->reg_pmcs));
+	pci_set_power_state(pdev, PCI_D3hot);
+#endif
 
 	return 0;
 }
 
 static int
+#ifdef JME_NEW_PM_API
 jme_resume(struct device *dev)
+#else
+jme_resume(struct pci_dev *pdev)
+#endif
 {
+#ifdef JME_NEW_PM_API
 	struct pci_dev *pdev = to_pci_dev(dev);
+#endif
 	struct net_device *netdev = pci_get_drvdata(pdev);
 	struct jme_adapter *jme = netdev_priv(netdev);
 
-	if (!netif_running(netdev))
-		return 0;
-
 	jme_clear_pm(jme);
+#ifndef JME_NEW_PM_API
+	pci_set_power_state(pdev, PCI_D0);
+	pci_restore_state(pdev);
+#endif
+
 	jme_phy_on(jme);
 	if (test_bit(JME_FLAG_SSET, &jme->flags))
 		jme_set_settings(netdev, &jme->old_ecmd);
@@ -3326,15 +3597,23 @@
 	return 0;
 }
 
+#ifdef JME_NEW_PM_API
 static SIMPLE_DEV_PM_OPS(jme_pm_ops, jme_suspend, jme_resume);
 #define JME_PM_OPS (&jme_pm_ops)
+#endif
 
 #else
 
+#ifdef JME_NEW_PM_API
 #define JME_PM_OPS NULL
 #endif
+#endif
 
-static const struct pci_device_id jme_pci_tbl[] = {
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,24)
+static struct pci_device_id jme_pci_tbl[] = {
+#else
+static DEFINE_PCI_DEVICE_TABLE(jme_pci_tbl) = {
+#endif
 	{ PCI_VDEVICE(JMICRON, PCI_DEVICE_ID_JMICRON_JMC250) },
 	{ PCI_VDEVICE(JMICRON, PCI_DEVICE_ID_JMICRON_JMC260) },
 	{ }
@@ -3346,7 +3625,12 @@
 	.probe          = jme_init_one,
 	.remove         = jme_remove_one,
 	.shutdown       = jme_shutdown,
+#ifndef JME_NEW_PM_API
+	.suspend        = jme_suspend,
+	.resume         = jme_resume
+#else
 	.driver.pm	= JME_PM_OPS,
+#endif
 };
 
 static int __init
Index: linux-3.17.7/drivers/net/ethernet/jme.h
===================================================================
--- linux-3.17.7.orig/drivers/net/ethernet/jme.h	2014-12-16 18:37:26.000000000 +0100
+++ linux-3.17.7/drivers/net/ethernet/jme.h	2015-01-11 16:44:13.372918000 +0100
@@ -27,7 +27,8 @@
 #include <linux/interrupt.h>
 
 #define DRV_NAME	"jme"
-#define DRV_VERSION	"1.0.8"
+#define DRV_VERSION	"1.0.8.9-jmmod-noasd-wol"
+#define PFX		DRV_NAME ": "
 
 #define PCI_DEVICE_ID_JMICRON_JMC250	0x0250
 #define PCI_DEVICE_ID_JMICRON_JMC260	0x0260
@@ -42,6 +43,15 @@
 	NETIF_MSG_TX_ERR | \
 	NETIF_MSG_HW)
 
+#ifndef pr_err
+#define pr_err(fmt, arg...) \
+	printk(KERN_ERR fmt, ##arg)
+#endif
+#ifndef netdev_err
+#define netdev_err(netdev, fmt, arg...) \
+	pr_err(fmt, ##arg)
+#endif
+
 #ifdef TX_DEBUG
 #define tx_dbg(priv, fmt, args...)					\
 	printk(KERN_DEBUG "%s: " fmt, (priv)->dev->name, ##args)
@@ -53,6 +63,82 @@
 } while (0)
 #endif
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,10,0)
+#define __vlan_hwaccel_put_tag(x,y) __vlan_hwaccel_put_tag(x, htons(ETH_P_8021Q), y)
+#define NETIF_F_HW_VLAN_TX NETIF_F_HW_VLAN_CTAG_TX_BIT
+#define NETIF_F_HW_VLAN_RX NETIF_F_HW_VLAN_CTAG_RX_BIT
+#endif
+
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,33)
+#define jme_msg(msglvl, type, priv, fmt, args...) \
+	if (netif_msg_##type(priv)) \
+		printk(msglvl "%s: " fmt, (priv)->dev->name, ## args)
+
+#define msg_probe(priv, fmt, args...) \
+	jme_msg(KERN_INFO, probe, priv, fmt, ## args)
+
+#define msg_link(priv, fmt, args...) \
+	jme_msg(KERN_INFO, link, priv, fmt, ## args)
+
+#define msg_intr(priv, fmt, args...) \
+	jme_msg(KERN_INFO, intr, priv, fmt, ## args)
+
+#define msg_rx_err(priv, fmt, args...) \
+	jme_msg(KERN_ERR, rx_err, priv, fmt, ## args)
+
+#define msg_rx_status(priv, fmt, args...) \
+	jme_msg(KERN_INFO, rx_status, priv, fmt, ## args)
+
+#define msg_tx_err(priv, fmt, args...) \
+	jme_msg(KERN_ERR, tx_err, priv, fmt, ## args)
+
+#define msg_tx_done(priv, fmt, args...) \
+	jme_msg(KERN_INFO, tx_done, priv, fmt, ## args)
+
+#define msg_tx_queued(priv, fmt, args...) \
+	jme_msg(KERN_INFO, tx_queued, priv, fmt, ## args)
+
+#define msg_hw(priv, fmt, args...) \
+	jme_msg(KERN_ERR, hw, priv, fmt, ## args)
+
+#ifndef netif_info
+#define netif_info(priv, type, dev, fmt, args...) \
+	msg_ ## type(priv, fmt, ## args)
+#endif
+#ifndef netif_err
+#define netif_err(priv, type, dev, fmt, args...) \
+	msg_ ## type(priv, fmt, ## args)
+#endif
+#endif
+
+#ifndef NETIF_F_TSO6
+#define NETIF_F_TSO6 0
+#endif
+#ifndef NETIF_F_IPV6_CSUM
+#define NETIF_F_IPV6_CSUM 0
+#endif
+
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
+#define __NO_BOOL__
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,0,0)
+#define __USE_NDO_FIX_FEATURES__
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,1,0)
+#define __UNIFY_VLAN_RX_PATH__
+#define __USE_NDO_SET_RX_MODE__
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,2,0)
+#define __USE_SKB_FRAG_API__
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,3,0)
+#define __NEW_FIX_FEATURES_TYPE__
+#endif
+
 /*
  * Extra PCI Configuration space interface
  */
@@ -387,10 +473,75 @@
 	atomic_t nr_free;
 };
 
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,18)
+#define false 0
+#define true 0
+#define netdev_alloc_skb(dev, len) dev_alloc_skb(len)
+#define PCI_VENDOR_ID_JMICRON           0x197B
+#endif
+
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,19)
+#define PCI_VDEVICE(vendor, device)             \
+        PCI_VENDOR_ID_##vendor, (device),       \
+        PCI_ANY_ID, PCI_ANY_ID, 0, 0
+#endif
+
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,21)
+#define NET_STAT(priv) priv->stats
+#define NETDEV_GET_STATS(netdev, fun_ptr) \
+	netdev->get_stats = fun_ptr
+#define DECLARE_NET_DEVICE_STATS struct net_device_stats stats;
+/*
+ * CentOS 5.2 have *_hdr helpers back-ported
+ */
+#ifdef RHEL_RELEASE_CODE
+#if RHEL_RELEASE_CODE < RHEL_RELEASE_VERSION(5,2)
+#define __DEFINE_IPHDR_HELPERS__
+#endif
+#else
+#define __DEFINE_IPHDR_HELPERS__
+#endif
+#else
 #define NET_STAT(priv) (priv->dev->stats)
 #define NETDEV_GET_STATS(netdev, fun_ptr)
 #define DECLARE_NET_DEVICE_STATS
+#endif
+
+#ifdef __DEFINE_IPHDR_HELPERS__
+static inline struct iphdr *ip_hdr(const struct sk_buff *skb)
+{
+	return skb->nh.iph;
+}
+
+static inline struct ipv6hdr *ipv6_hdr(const struct sk_buff *skb)
+{
+	return skb->nh.ipv6h;
+}
+
+static inline struct tcphdr *tcp_hdr(const struct sk_buff *skb)
+{
+	return skb->h.th;
+}
+#endif
 
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,23)
+#define DECLARE_NAPI_STRUCT
+#define NETIF_NAPI_SET(dev, napis, pollfn, q) \
+	dev->poll = pollfn; \
+	dev->weight = q;
+#define JME_NAPI_HOLDER(holder) struct net_device *holder
+#define JME_NAPI_WEIGHT(w) int *w
+#define JME_NAPI_WEIGHT_VAL(w) *w
+#define JME_NAPI_WEIGHT_SET(w, r) *w = r
+#define DECLARE_NETDEV struct net_device *netdev = jme->dev;
+#define JME_RX_COMPLETE(dev, napis) netif_rx_complete(dev)
+#define JME_NAPI_ENABLE(priv) netif_poll_enable(priv->dev);
+#define JME_NAPI_DISABLE(priv) netif_poll_disable(priv->dev);
+#define JME_RX_SCHEDULE_PREP(priv) \
+	netif_rx_schedule_prep(priv->dev)
+#define JME_RX_SCHEDULE(priv) \
+	__netif_rx_schedule(priv->dev);
+#else
 #define DECLARE_NAPI_STRUCT struct napi_struct napi;
 #define NETIF_NAPI_SET(dev, napis, pollfn, q) \
 	netif_napi_add(dev, napis, pollfn, q);
@@ -398,6 +549,7 @@
 #define JME_NAPI_WEIGHT(w) int w
 #define JME_NAPI_WEIGHT_VAL(w) w
 #define JME_NAPI_WEIGHT_SET(w, r)
+#define DECLARE_NETDEV
 #define JME_RX_COMPLETE(dev, napis) napi_complete(napis)
 #define JME_NAPI_ENABLE(priv) napi_enable(&priv->napi);
 #define JME_NAPI_DISABLE(priv) \
@@ -407,6 +559,18 @@
 	napi_schedule_prep(&priv->napi)
 #define JME_RX_SCHEDULE(priv) \
 	__napi_schedule(&priv->napi);
+#endif
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,38)
+#define JME_NEW_PM_API
+#endif
+
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,26)
+static inline __u32 ethtool_cmd_speed(struct ethtool_cmd *ep)
+{
+	return ep->speed;
+}
+#endif
 
 /*
  * Jmac Adapter Private data
@@ -433,7 +597,6 @@
 	u32			reg_rxmcs;
 	u32			reg_ghc;
 	u32			reg_pmcs;
-	u32			reg_gpreg1;
 	u32			phylink;
 	u32			tx_ring_size;
 	u32			tx_ring_mask;
@@ -449,6 +612,9 @@
 	u32			msg_enable;
 	struct ethtool_cmd	old_ecmd;
 	unsigned int		old_mtu;
+#ifndef __UNIFY_VLAN_RX_PATH__
+	struct vlan_group	*vlgrp;
+#endif
 	struct dynpcc_info	dpi;
 	atomic_t		intr_sem;
 	atomic_t		link_changing;
@@ -456,13 +622,31 @@
 	atomic_t		rx_cleaning;
 	atomic_t		rx_empty;
 	int			(*jme_rx)(struct sk_buff *skb);
+#ifndef __UNIFY_VLAN_RX_PATH__
+	int			(*jme_vlan_rx)(struct sk_buff *skb,
+					  struct vlan_group *grp,
+					  unsigned short vlan_tag);
+#endif
 	DECLARE_NAPI_STRUCT
 	DECLARE_NET_DEVICE_STATS
 };
 
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,21)
+static struct net_device_stats *
+jme_get_stats(struct net_device *netdev)
+{
+	struct jme_adapter *jme = netdev_priv(netdev);
+	return &jme->stats;
+}
+#endif
+
 enum jme_flags_bits {
 	JME_FLAG_MSI		= 1,
 	JME_FLAG_SSET		= 2,
+#ifndef __USE_NDO_FIX_FEATURES__
+	JME_FLAG_TXCSUM		= 3,
+	JME_FLAG_TSO		= 4,
+#endif
 	JME_FLAG_POLL		= 5,
 	JME_FLAG_SHUTDOWN	= 6,
 };
@@ -471,6 +655,15 @@
 #define JME_REG_LEN		0x500
 #define MAX_ETHERNET_JUMBO_PACKET_SIZE 9216
 
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,23)
+static inline struct jme_adapter*
+jme_napi_priv(struct net_device *holder)
+{
+	struct jme_adapter *jme;
+	jme = netdev_priv(holder);
+	return jme;
+}
+#else
 static inline struct jme_adapter*
 jme_napi_priv(struct napi_struct *napi)
 {
@@ -478,6 +671,7 @@
 	jme = container_of(napi, struct jme_adapter, napi);
 	return jme;
 }
+#endif
 
 /*
  * MMaped I/O Resters
@@ -834,8 +1028,6 @@
  */
 enum jme_ghc_bit_mask {
 	GHC_SWRST		= 0x40000000,
-	GHC_TO_CLK_SRC		= 0x00C00000,
-	GHC_TXMAC_CLK_SRC	= 0x00300000,
 	GHC_DPX			= 0x00000040,
 	GHC_SPEED		= 0x00000030,
 	GHC_LINK_POLL		= 0x00000001,
@@ -1016,17 +1208,18 @@
 
 /*
  * General Purpose REG-1
+ * Note: All theses bits defined here are for
+ *       Chip mode revision 0x11 only
  */
-enum jme_gpreg1_bit_masks {
-	GPREG1_RXCLKOFF		= 0x04000000,
-	GPREG1_PCREQN		= 0x00020000,
-	GPREG1_HALFMODEPATCH	= 0x00000040, /* For Chip revision 0x11 only */
-	GPREG1_RSSPATCH		= 0x00000020, /* For Chip revision 0x11 only */
+enum jme_gpreg1_masks {
 	GPREG1_INTRDELAYUNIT	= 0x00000018,
 	GPREG1_INTRDELAYENABLE	= 0x00000007,
 };
 
 enum jme_gpreg1_vals {
+	GPREG1_HALFMODEPATCH	= 0x00000040,
+	GPREG1_RSSPATCH		= 0x00000020,
+
 	GPREG1_INTDLYUNIT_16NS	= 0x00000000,
 	GPREG1_INTDLYUNIT_256NS	= 0x00000008,
 	GPREG1_INTDLYUNIT_1US	= 0x00000010,
@@ -1040,7 +1233,7 @@
 	GPREG1_INTDLYEN_6U	= 0x00000006,
 	GPREG1_INTDLYEN_7U	= 0x00000007,
 
-	GPREG1_DEFAULT		= GPREG1_PCREQN,
+	GPREG1_DEFAULT		= 0x00000000,
 };
 
 /*
@@ -1276,3 +1469,4 @@
 static void jme_set_multi(struct net_device *netdev);
 
 #endif
+
